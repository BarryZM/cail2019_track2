# cail2019_track2
中国法研杯CAIL2019要素抽取任务第三名方案分享
====
这次比赛虽然是第三名，但是和前面的大佬们差距很大，足足1.8个百分点的差距，（我也不知道自己为什么就到了第三）.....
趁国庆放假，我也把代码整理了一下。第一次参加比赛，代码写的乱七八糟的，好多实验也没记录，大家见谅....下边是我的方案介绍，第一阶段没怎么弄，就直接bert提交就是69.+，所以就不介绍了，主要介绍第二阶段的方法。第一次用git，可能很多地方写得不好，在此表示抱歉（本科机械狗。。没接触过git）

方案介绍
------
### 任务简介
根据给定司法文书中的相关段落，识别相应的关键案情要素，其中每个句子对应的类别标签个数不定，属于多标签问题。任务共涉及三个领域，包括婚姻家庭、劳动争议、借款合同。在这次比赛中，我用的是最原始的方式，使用sigmoid做激活函数多标签分类。
### 任务难点
看过数据的应该都知道，这次比赛数据的正负例样本分布不均衡，甚至有的标签（比如LN12）只有一个正例，导致模型基本对这种标签的得分基本为0。
### 解决方案简介
对于正负例样本不均衡的问题，首先我使用的是focal loss，Kaiming大神的这个loss真的是太厉害了，一下就给我从69.+提到了70.+。之后又尝试了阈值移动，这次我只是随机切分了一下数据集，用切分的测试集取搜索阈值，由于bert跑得很慢，实验室GPU也很紧张，所以没有采用交叉验证的方式，阈值移动使我的线上从70提到了71。

对于那种正例很少的标签数据，我们队伍采用的是规则的方式来做，规则这部分工作是我们的队伍的另外一个队员做的，他的队伍一开始叫牧笛，后来和我合并了。规则的实验方式是正则表达式，我们通过正则表达式去匹配句子，匹配上了就让这个句子在规则对应的这个标签置1，最后对模型的结果和规则的结果取并集。规则提分也很大，我从71提到的72左右。具体规则我就不写出来了，就随便举个例子，剩下的自己去发现吧。

比如LN12，根据它的标签解释：担保合同无效|撤销|解除， 我们再从它仅有的一条数据中大致提取了一条规则

['.*(保证合同|抵押合同|借款合同).*(无效|不发生效力).*']

这条规则贡献贼大，足足提了线上成绩0.5，其它一堆规则提的分加起来才有它的多。

### 预训练模型
这次采用的bert模型是googl开源的中文预训练模型，尝试过wwm，但是不知道为啥在我这里没有提升，刚刚看了第二名大佬的分享，好像用的Roberta，当时也没找到这个的中文开源模型，所以没有做过实验，看了大佬的分享，好像提升很大。

因为比赛数据是司法领域的，所以我使用比赛数据和一些爬取的判决书做预训练，然后再用这个模型去做多标签分类，这个方法提升很大，直接就到了73的行列。我额外加的数据只有在劳动争议上有提升，在婚姻家庭和借款合同上降了，所以这两个类别就只用了比赛数据做预训练。

### 模型结构
采用的bert+rcnn，一开始使最大池化成绩降了，后来我把最大池化改为self attention，相对原始bert提升了零点几个百分点。

### 数据增强
我尝试了eda，回译，线下提升了，线上结果降了。。真的是线下操作猛如虎，一到线上0.5。最后在divorce类型和loan类型数据上，copy了一下少量数据就提了零点几。感觉很玄学。

代码说明
-------
具体参数都在代码里，自己进去稍作路径修改就行了，我整理的时候跑通过的。下边只是简单说明哪个代码是干啥的。这些代码是在google的bert基础上改的。

### 基本代码
训练

CUDA_VISIBLE_DEVICES=1 python train.py

将ckpt转为pb

CUDA_VISIBLE_DEVICES=1 python convert.py

线下测试

CUDA_VISIBLE_DEVICES=1 python evaluation.py

### 如果需要额外预训练的话，使用以下代码

创建预训练数据txt

python genPretrainData.py

创建预训练数据的tfrecord文件

python createPretrainData.py

预训练

CUDA_VISIBLE_DEVICES=1 python run_pretrain.py

总结
-----
感觉没啥可说的，东西都在上边了，排版很丑..第一次写github，等我再下去学学再来修改readme。
